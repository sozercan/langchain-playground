{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import Playlist\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_id = \"PLj6h78yzYM2Mwt-aVXI6ItZX5s9izAp0F\"\n",
    "playlist_link = \"https://www.youtube.com/playlist?list=\" + playlist_id\n",
    "youtube_url_list = Playlist(playlist_link).video_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url_list = [\"https://www.youtube.com/watch?v=C_78DM8fG6E\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=0)\n",
    "\n",
    "for url in youtube_url_list:\n",
    "    try:\n",
    "        loader = YoutubeLoader.from_youtube_url(url, add_video_info=False)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    result = loader.load()\n",
    "\n",
    "    texts.extend(text_splitter.split_documents(result))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(texts)\n",
    "\n",
    "# select which embeddings we want to use\n",
    "embeddings = OpenAIEmbeddings(chunk_size=1)\n",
    "\n",
    "# create the vectorestore to use as the index\n",
    "db = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "# expose this index in a retriever interface\n",
    "retriever = db.as_retriever(search_type=\"similarity\") #, search_kwargs={\"k\":1})\n",
    "\n",
    "# create a chain to answer questions\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=AzureOpenAI(temperature=0, deployment_name=\"text-davinci-003\"), chain_type=\"map_reduce\", retriever=retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the implications of AI?\"\n",
    "\n",
    "result = qa({\"query\": query})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "\n",
    "template = \"\"\"You are a teacher in physics for High School student. Given the text of question, it is your job to write a answer that question with example.\n",
    "{chat_history}\n",
    "Human: {question}\n",
    "AI:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"chat_history\",\"question\"], template=template)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=AzureOpenAI(temperature=0, deployment_name=\"text-davinci-003\"),\n",
    "    prompt=prompt_template,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "OpenAI()\n",
    "\n",
    "llm_chain.predict(question=\"What are the implications of AI?\")\n",
    "\n",
    "result = llm_chain.predict(question=\"What is Joules?\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
